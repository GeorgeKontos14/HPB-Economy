{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Clustering of Countries Economic Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook aims to investigate if spectral clustering can be applied for the task of grouping the financial growth of 113 countries over the past 58 years. The whole process is documented step by step.\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import csv\n",
    "\n",
    "import warnings\n",
    "\n",
    "from tslearn.clustering import silhouette_score\n",
    "\n",
    "import Constants\n",
    "\n",
    "from Utils import DataUtils, PreProcessing, VisualUtils, TimeSeriesUtils, PostProcessing\n",
    "\n",
    "from Clustering import SpectralClustering, KernelKMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "For each country, three different time series of data are considered; the annual evolution of its GDP per capita, the annual evolution of its population and the annual evolution of the bilateral exchange rate of its currency against the US Dollar. While there is (partially) available data for the GDP and population evolution all the way from 1900, data about currency exchange rates is only available since 1960. For all three time series, the latest data concerns 2017. In order to stabilize the dataset, all GDP and population data before 1960 is discarded.\n",
    "\n",
    "Because the GDP time series present very high variance, the logarithm of the series is taken instead to smoothen the results.\n",
    "\n",
    "The data for each time series is loaded from a `.csv` file to create a $113 \\times T$ matrix, where $T$ is the amount of years each time series is available for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, gdp, pop, currency, map = DataUtils.load_clustering_data()\n",
    "locations = DataUtils.load_locations()\n",
    "groups = DataUtils.load_groups()\n",
    "gdp_data = np.log(gdp[:, -Constants.T:])\n",
    "pop_data = pop[:, -Constants.T:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Before the clustering algorithms are applied, the time series data is concatenated for all countries and then standardized.\n",
    "\n",
    "One complication that arises for currency exchange rate data when it comes to countries of former Yugoslavia and USSR. For these countries (Serbia, Croatia, Bosnia and Herzegovina and Russia respectively) no data is available until 1990. To tackle this problem, a nearest neighbor imputer is used to fill the empty values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, scaled_df = PreProcessing.preprocess(\n",
    "    names, gdp_data, pop_data, currency\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gdp, scaled_df_gdp, scaled_data_gdp = PreProcessing.preprocess_onlyGDP(names, gdp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Clustering\n",
    "\n",
    "We examine three different ways of building the similarity graph; a euclidean $k$-nearest neighbor graph, an $\\epsilon$-neighborhood graph and a DTW $k$-nearest neighbor graph.\n",
    "\n",
    "In order to tune the number of clusters for the algorithm, the 'eigenvalue' heuristic is used. Specifically, we examine the magnitude of the eigenvalues of the Laplacian matrix of the graph $L$, and take K clusters such that the smallest eigenvalues $\\lambda_1$, ..., $\\lambda_K$ are significantly smaller than the rest. Afterwards, we examine the information captured by the corresponding eigenvectors. We reduce the number of clusters by one for each eigenvector that does not capture any significant information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $k$-nearest neighbor graph:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use $k=\\lfloor \\sqrt{n} \\rfloor$ neighbors, where $n$ is the number of countries, i.e. 113. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_knn = SpectralClustering.knn_graph(scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvals_knn_norm, eigvecs_knn_norm = SpectralClustering.laplacian_eigen(\n",
    "    W_knn, True, True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude 3 clusters are sufficient. We create the H matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_knn = 3\n",
    "H_knn = SpectralClustering.smallest_eigenvecs(\n",
    "    K_knn, eigvals_knn_norm, eigvecs_knn_norm, True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the eigenvectors are relevant, so now we can perform the clustering with 3 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_knn = SpectralClustering.kmeans(\n",
    "    H_knn, 3\n",
    ")\n",
    "\n",
    "score_knn = silhouette_score(scaled_data_gdp, labels_knn)\n",
    "cluster_centers_knn = TimeSeriesUtils.cluster_centroids(scaled_data_gdp, 3, labels_knn)\n",
    "clusters = VisualUtils.show_clustering(\n",
    "    names, \n",
    "    3, \n",
    "    scaled_data_gdp, \n",
    "    cluster_centers_knn, \n",
    "    labels_knn, \n",
    "    score_knn, \n",
    "    2, \n",
    "    2,\n",
    "    \"Spectral Clustering with Euclidean k-neighbors\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\epsilon$-neighborhood graph:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for the similarity graph to be sparse, we set $\\epsilon$ to the 10th percentile of the distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_eps = SpectralClustering.epsilon_graph(\n",
    "    scaled_df, 10, True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvals_eps_norm, eigvecs_eps_norm = SpectralClustering.laplacian_eigen(\n",
    "    W_eps, True, True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude 21 clusters are sufficient. We create the H matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_eps = 21\n",
    "H_eps = SpectralClustering.smallest_eigenvecs(\n",
    "    K_eps, eigvals_eps_norm, eigvecs_eps_norm, True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two different eigenvectors give no information, so we can reduce the number of clusters to 19:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_eps = SpectralClustering.kmeans(\n",
    "    H_eps, K_eps-2\n",
    ")\n",
    "score_eps = silhouette_score(scaled_data_gdp, labels_eps)\n",
    "cluster_centers_eps = TimeSeriesUtils.cluster_centroids(scaled_data_gdp, K_eps-2, labels_eps)\n",
    "clusters = VisualUtils.show_clustering(\n",
    "    names, \n",
    "    K_eps-2, \n",
    "    scaled_data_gdp, \n",
    "    cluster_centers_eps, \n",
    "    labels_eps, \n",
    "    score_eps, \n",
    "    4, \n",
    "    5,\n",
    "    \"Spectral Clustering with epsilon neighborhood\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Clustering, Dynamic Time Warping and Kernel $k$-Means\n",
    "\n",
    "Here, we construct a $k$-neighbors graph similar to the one before, but with a different distance measure. Instead of Euclidean Distance, Dynamic Time Warpint (DTW) is used to better capture the similaritites and differences of time series. Instead of the concatenated dataset, this section only considers the GDP time series, as it is the one of the highest significance and variance.\n",
    "\n",
    "As suggested by previous work, this version of spectral clustering can provide an initial partition to be used for spectral clustering. For this reason, we have predetermined the number of clusters to 6, as this is the optimal number of clusters for kernel k-means according to the elbow plot heuristic. We can see, however, that the eigenvalue plot indicates 6 is a reasonable choice, as there is a clear gap between the 6th and 7th smallest eigenvalues, and all 6 corresonding eigenvectors are informative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_dtw = SpectralClustering.dtw_knn_graph(n, scaled_df_gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvals_dtw_norm, eigvecs_dtw_norm = SpectralClustering.laplacian_eigen(\n",
    "    n, W_dtw, True, True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_dtw = 6\n",
    "H_dtw = SpectralClustering.smallest_eigenvecs(\n",
    "    K_dtw, eigvals_dtw_norm, eigvecs_dtw_norm, True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dtw = SpectralClustering.kmeans(\n",
    "    H_dtw, K_dtw\n",
    ")\n",
    "\n",
    "score_dtw = silhouette_score(scaled_data_gdp, labels_dtw)\n",
    "cluster_centers_dtw = TimeSeriesUtils.cluster_centroids(scaled_data_gdp, K_dtw, labels_dtw)\n",
    "clusters = VisualUtils.show_clustering(\n",
    "    names, \n",
    "    K_dtw, \n",
    "    scaled_data_gdp, \n",
    "    cluster_centers_dtw, \n",
    "    labels_dtw, \n",
    "    score_dtw, \n",
    "    3, \n",
    "    2,\n",
    "    \"Spectral Clustering with DTW\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    kkmeans = KernelKMeans.NonRandomKernelKMeans(6, labels_dtw)\n",
    "    y_kkmeans = kkmeans.fit_predict(scaled_df_gdp)\n",
    "\n",
    "score_kkmeans = silhouette_score(scaled_data_gdp, y_kkmeans)\n",
    "# cluster_centers_kkmeans = TimeSeriesUtils.cluster_centroids(scaled_data_gdp, K_dtw, y_kkmeans, T_currency)\n",
    "clusters = VisualUtils.show_clustering(\n",
    "    names, \n",
    "    K_dtw, \n",
    "    gdp_data, \n",
    "    None, \n",
    "    y_kkmeans, \n",
    "    score_kkmeans, \n",
    "    3, \n",
    "    2, \n",
    "    \"Kernel 6-Means with Spectral Clustering Initialization\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm produces well-structured clusters and achieves a considerable silhouette score. We visualize the results on a map and we display how the clustering corresponds to commonly accepted groupings of countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VisualUtils.show_clusters_on_map(names, y_kkmeans, map, 'Kernel 6-Means with GAK and Spectral Clustering Initialization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PostProcessing.postprocess_clustering(scaled_data_gdp, locations, names, groups, y_kkmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(labels_spec_path, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Country', 'Cluster'])\n",
    "#     for i, name in enumerate(names):\n",
    "#         writer.writerow([name, y_kkmeans[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataUtils.write_data(scaled_data_gdp, scaled_gdp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "While spectral clustering on its own does not produce desirable results, it can enhance the performance of kernel $k$-means to produce the best partition of all the examined algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

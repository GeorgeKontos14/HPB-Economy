{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Clustering of Countries Economic Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The aim of this notebook is to determine which hierarchical clustering algorithm is optimal for the task of grouping the financial growth of 113 countries over the past 58 years. The whole process is documented step by step.\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tslearn.clustering import silhouette_score\n",
    "\n",
    "from Utils import DataUtils, PreProcessing, TimeSeriesUtils, VisualUtils\n",
    "\n",
    "from Clustering import Outliers, HierarchicalClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "For each country, three different time series of data are considered; the annual evolution of its GDP per capita, the annual evolution of its population and the annual evolution of the bilateral exchange rate of its currency against the US Dollar. While there is (partially) available data for the GDP and population evolution all the way from 1900, data about currency exchange rates is only available since 1960. For all three time series, the latest data concerns 2017. In order to stabilize the dataset, all GDP and population data before 1960 is discarded.\n",
    "\n",
    "Because the GDP time series present very high variance, the logarithm of the series is taken instead to smoothen the results.\n",
    "\n",
    "The data for each time series is loaded from a `.csv` file to create a $113 \\times T$ matrix, where $T$ is the amount of years each time series is available for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 113\n",
    "T_gdp = 118\n",
    "T_pop = 118\n",
    "T_currency = 58\n",
    "\n",
    "start_year = 1960\n",
    "\n",
    "names_path = \"Data/names.txt\"\n",
    "gdp_path = \"Data/yp_raw.csv\"\n",
    "population_path = \"Data/pop_raw.csv\"\n",
    "currency_path = \"Data/currency.csv\"\n",
    "map_path = \"Data/Map/ne_110m_admin_0_countries.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, gdp, pop, currency, map = DataUtils.load_clustering_data(\n",
    "    names_path, gdp_path, population_path, currency_path, map_path, n, T_gdp, T_pop, T_currency\n",
    ")\n",
    "gdp_data = np.log(gdp[:, -T_currency:])\n",
    "pop_data = pop[:, -T_currency:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset consists of three different time series for each country, it would be irrational to construct feature vectors by concatenating the time series. Instead, Principal Component Analysis is performed on each time series to determine the components that capture the most variance. By specifying the variance, the PCA  implementation from sklearn automatically determines the number of components for each dataset.\n",
    "\n",
    "Once the principal components for each series are computed and concatenated, standard scaling is performed to normalize the dataset.\n",
    "\n",
    "One complication that arises for currency exchange rate data when it comes to countries of former Yugoslavia and USSR. For these countries (Serbia, Croatia, Bosnia and Herzegovina and Russia respectively) no data is available until 1990. To tackle this problem, a nearest neighbor imputer is used to fill the empty values. While this is not indicative of the actual values for that period, it ensures the consistency of the dataset. This imputation is performed before the PCA algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = 0.95\n",
    "df, scaled_df = PreProcessing.preprocess_pca(\n",
    "    names, gdp_data, pop_data, currency, 0.95\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection\n",
    "\n",
    "In order to detect and eliminate outliers from the dataset (i.e. countries that behave in a way dissimilar to all others), the DBSCAN clustering algorithm is employed. In order to tune the `eps` and `min_samples` parameters, the following heuristics are used:\n",
    "- The `eps` parameter is set to the point of maximum curvature in the $k$-Distance Graph of the dataset.\n",
    "- The `min_samples` parameter is set to twice the number of features in the dataset.\n",
    "\n",
    "The first two tables displayed by the following python cell summarize the data in the dataset before and after outlier detection. The third table lists the countries that have been labeled as outliers. These countries are discarded from the dataset.\n",
    "\n",
    "The plot displayed presents the $k$-Distance Graph of the dataset, for $k=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "without_outliers, outliers, without_outliers_countries, outliers_countries = Outliers.remove_outliers_dbscan(\n",
    "    names, scaled_df, True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering Algorithms\n",
    "\n",
    "In this section, hierarchical clustering of the countries is performed with four different linkage methods, namely complete, average, single and ward linkage.\n",
    "\n",
    "For each linkage method, the distance threshold for splitting clusters is determined by MATLAB(TM). Namely the threshold is set to $0.7 * \\text{max}(\\text{distance})$. The number of clusters, the distribution of values and the silhoutte score are printed for each algorithm. Furthermore, the hierarchy is printed in the form of a dendogram to visualize the clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_labels, complete_score = HierarchicalClustering.hierarchical_clustering(\n",
    "    without_outliers, 'complete', True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_labels, average_score = HierarchicalClustering.hierarchical_clustering(\n",
    "    without_outliers, 'average', True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_labels, single_score = HierarchicalClustering.hierarchical_clustering(\n",
    "    without_outliers, 'single', True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ward Linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ward_labels, ward_score = HierarchicalClustering.hierarchical_clustering(\n",
    "    without_outliers, 'ward', True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In conclusion, it seems like ward linkage is better suited for this problem, as it produces more balanced clusters and achieves the highest silhoutte score. This applies to 108 countries, since China, Indonesia, India, Iran and Vietnam are considered outliers. We now give a visualization of the proposed clusters, where the explicit centroids have been calculated using DTW Barycenter Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gdp, scaled_df_gdp, scaled_data_gdp = PreProcessing.preprocess_onlyGDP(names, gdp_data, start_year, T_currency)\n",
    "ward_labels -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_outliers = df_gdp.loc[without_outliers_countries]\n",
    "df_outliers = df_gdp.loc[outliers_countries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = silhouette_score(df_no_outliers, ward_labels)\n",
    "# cluster_centers = TimeSeriesUtils.cluster_centroids(df_no_outliers.values, 3, ward_labels, T_currency)\n",
    "clusters = VisualUtils.show_clustering(\n",
    "    without_outliers_countries,\n",
    "    3,\n",
    "    df_no_outliers.values,\n",
    "    None,\n",
    "    ward_labels,\n",
    "    score,\n",
    "    3,\n",
    "    1,\n",
    "    start_year,\n",
    "    T_currency,\n",
    "    \"Hierachical Clustering with Ward Linkage\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we can clearly detect intracluster similarities, the clusters are not well seperated. This is well depected in the silhoutte score of the algorithm to (when taken against the scaled data and not the PCA-reduced dataset).\n",
    "\n",
    "At last, we take a look on the outliers and the centroids, to see if any of the outliers would fit into the existing clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VisualUtils.plot_centroids_outliers(\n",
    "#     cluster_centers, \n",
    "#     df_outliers.values, \n",
    "#     start_year, \n",
    "#     T_currency, \n",
    "#     \"Centroids and Outliers for hierarchical clustering\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some ot the outliers are very simiar to the centroids,, even though they provide significant improvement on the performance on the PCA-reduced data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
